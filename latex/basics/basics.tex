\chapter{Grundlagen}
\label{chapter:basics}

Im folgenden sollen Verfahren und Techniken erläutert werden, welche für das Verständnis der späteren Kapitel essenziell sind.

\section{Virtuelle Speicherverwaltung}

Virtuelle Speicherverwaltung stellt eine Abstraktion für die vorhandenen physikalischen Speichermedien wie etwa dem Hauptspeicher oder der Festplatte bereit.
Das Betriebssystem übersetzt virtuelle Adressen, welche von Prozessen genutzt werden, mit Hilfe der Hardware in physikalische Adressen. 
Jedem Prozess steht der gleiche virtuelle Adressraum zur Verfügung, wobei das Betriebssystem dafür Sorge trägt für jeden Prozess die richtige Zuordnung von virtueller zu physikalischer Adresse sicherzustellen.
Ein Vorteil der virtuellen Speicherverwaltung ist eine erhöhte Sicherheit durch die Speicherisolierung aller Prozesse. 
So kann eine fehlerhafte Schreiboperation eines Prozesses keinen Fehler in anderen Prozessen verursachen, da gleiche virtuelle Adressen vom Betriebssystem auf unterschiedliche physikalische Adressen abgebildet werden. 
Des Weiteren kann ein Prozess mehr Hauptspeicher nutzen als physikalisch vorhanden ist, indem Daten vom Betriebssystem auf andere Speichermedien wie die Festplatte ausgelagert werden. Hiermit werden beispielsweise Anwendungsentwickler entlastet, da sie ihre Software nicht für Systeme mit weniger Hauptspeicher gesondert anpassen müssen.

\section{Caches}

Die Geschwindigkeitsentwicklung des Hauptspeichers konnte in den letzten Jahren nicht mit der des Prozessors Schritt halten. Der Cache ist ein im Vergleich zum Hauptspeicher kleinerer, aber schnellerer Pufferspeicher, welcher im aktuellen Kontext häufig benötigte Daten vorhält. 
Ohne Caches wäre ein Prozessor häufig gezwungen auf Daten des langsamen Hauptspeichers zu warten und würde in seiner Verarbeitungsgeschwindigkeit ausgebremst. 
Auch in anderen Ebenen sind Caches sinnvoll, wie etwa im Browser, wobei in dieser Arbeit vor allem die Caches im Prozessor von Relevanz sind. 
Weiter liegt der Fokus der Arbeit auf die im Dekstopbereich weit verbreitete x86-Architektur, weshalb mit Intel-Prozessoren der Core-Architektur bestückte Testrechner verwendet werden, da Intels Core-Architektur im x86-Desktopsegment zurzeit den höchsten Marktanteil besitzt \cite{AMDIntelMarketShare}. Deshalb werden Erklärungen im Folgenden häufig mit Beispielen der Intel Core-Architektur veranschaulicht.

Ein Cache der Core-Architektur lagert nicht einzelne Bytes, sondern immer gleich 64 Bytes, Cache-Line genannt, auf einmal ein. Dabei werden die 64 Bytes beginnend ab der größten Adresse, welche zugleich kleiner als die Zieladresse und ein Vielfaches von 64 ist, angefragt.
Angenommen 4 Bytes Daten an Adresse 0b10110111 werden angefordert, dann lagert der Cache die 64 Bytes beginnend mit der Adresse 0b10000000 ein.
Heutige Arbeitsspeichermodule liefern 8 Bytes zeitgleich, wobei die CPU mit einem einzigen Befehl einen Burst von 8 Übertragungen initiieren kann, die das Lesen und Schreiben einer gesamten 64 Byte Cache-Line ermöglichen.
Daher ist der Performancenachteil, welcher durch ein Laden von gleich 64 Bytes entsteht, vernachlässigbar und wird von dem Vorteil überwogen, dass die zusätzlich geladenen Bytes mit hoher Wahrscheinlichkeit in den nächsten Zyklen ebenfalls benötigt werden.

Ein Prozessorcache besteht üblicherweise aus mehreren Ebenen, Cache-Level genannt, wobei die Core-Architektur etwa 3 Cache-Level besitzt, welche absteigend größer und langsamer werden. Ein Intel i7-4770 besitzt pro physischen Kern beispielsweise einen 32 KiB L1-Datencache mit einer Zugriffslatenz von 4-5 Taktzyklen und einen 256 KiB L2-Cache mit einer Latenz von 12 Taktzyklen \cite{CacheStatsHaswell}.
Im Unterschied zwischen den beiden ersten Cache-Leveln teilen sich in der Core-Architektur alle Kerne den L3-Cache. 
Dies bedeutet aus Angreifersicht einen großen Vorteil, da ein Programm den Zustand des L3-Caches beeinflusst, unabhängig davon auf welchem Kern es ausgeführt wird.
Dagegen muss die Angreiferin beim einem Angriff auf den L1- beziehungsweise L2-Cache sicherstellen, dass ihr Code und das angegriffene Programm auf dem selben physischen Kern ausgeführt werden.

Die Ersetzungsstrategie legt fest welcher Eintrag aus dem Cache verdrängt wird, sofern alle Einträge des zugehörigen Cache-Sets belegt sind. 
Intels Core-Prozessoren verdrängen typischerweise den Eintrag, welcher bezogen auf die letzte Zugriffszeit am ältesten ist, auch least-recently-used (LRU) Strategie genannt. 
Ab der Ivy-Bridge Generation passt Intel diese Strategie situationsbedingt an \cite{CacheReplacementPolicy}, wobei der Algorithmus hinter den Ersetzungsstrategien ebenfalls nicht öffentlich zugänglich ist.

\subsection{Assoziativität}

Sofern die Auswahl des Cache-Eintrags für die Daten einer bestimmten Hauptspeicheradresse keinerlei Beschränkungen unterliegt, wird von einem voll-assoziativen Cache gesprochen. 
Das andere Extrem wäre ein einfach-assoziativer Cache beziehungsweise eine direkte Abbildung, wobei die Adresse des Hauptspeichers von der die Daten stammen den zu wählenden Cache-Eintrag eindeutig festlegt.

Der L3-Cache eines Intel i7-4770 ist beispielsweise 8 MiB groß und verfügt daher über 131072($2^{17}$) Cache-Einträge der Größe einer Cache-Line. 
Wäre dieser Cache nun voll-assoziativ, müsste der Cache bei jeder Anfrage komplett durchsucht werden. Aus diesem Grund ist der Cache in Cache-Sets unterteilt, wobei Daten einer spezifischen Hauptspeicheradresse nur in genau ein Cache-Set eingelagert werden können. 
Der i7-4770 besitzt 8192 dieser Cache-Sets, womit sich eine Assoziativität von 16 ergibt (Anzahl der Cache-Einträge geteilt durch Anzahl der Cache-Sets), das heißt die Suche nach den Daten einer Hauptspeicheradresse im Cache ist auf 16 Einträge begrenzt. 
Die Zuordnung von Hauptspeicheradressen zu den Cache-Sets ist nicht öffentlich dokumentiert.

%Ein CPU-Cache enthält mehrere Einträge, welche folgende Bestandteile besitzen:
%\begin{enum}
%\item Cache-Line: Die gecacheten Daten, wobei die Länge in der Core-Architektur etwa 64 Bytes beträgt.
%\item Address-Tag: Die Adresse im Hauptspeicher von der die Daten in der Cache-Line stammen.
%\item Flag-Bits: Etwa das "Dirty"-Bit welches anzeigt ob die Daten der Cache-Line noch mit denen im Hauptspeicher übereinstimmen.
%\end{enum}

\subsection{Inclusive und Exclusive}
Ob die Inhalte eines Caches auch in anderen Cache-Leveln verfügbar sind, ist ein für diese Arbeit wichtiges Designkriterium. Ein Cache wird als Inclusive bezeichnet, sofern alle Daten die in einem niedrigen Cache-Level vorliegen zusätzlich auch in den höheren Cache-Leveln eingelagert sind. 
So besitzen die Caches aller Desktop-Versionen der Core-Architektur diese Eigenschaft (Stand Juni 2018). 
Die Caches der Desktop-Prozessoren des Konkurrenten AMD (beispielsweise Zen-Architektur \cite{CacheRyzen}) sowie der aktuellen Skylake-X Prozessoren \cite{CacheSkylakeX} für Intels High-Performance Plattform besitzen diese Eigenschaft nicht.
Wegen des großen Marktanteils von Intel kann festgehalten werden, dass der Großteil der sich im Einsatz befindlichen Prozessoren mit Inclusive Caches ausgestattet ist.

\section{Cache-Angriffe}

Cache-Angriffe beschreiben eine generelle Klasse von Mikro-Architektur Seitenkanalangriffen, welche den Cache, der als geteilte Ressource zwischen verschiedenen Prozessen fungiert, verwenden um Informationen abzugreifen. Durch diesen Angriff können sichere und unsichere Prozesse über den geteilten Cache ungeachtet höher liegender Schutzmechanismen wie virtualisiertem Speicher oder Hypervisor-Systemen kommunizieren. Eine Angreiferin könnte ein Programm entwickeln welches Informationen über den inneren Zustand eines anderen Prozesses sammelt und so AES-Schlüssel \cite{BernsteinAES}, RSA-Schlüssel \cite{CacheAttackRSA}, auch über die Grenzen von virtuellen Maschinen hinweg, abgreifen.

\subsection{Flush and Reload}

Ausgang dieses Angriffs ist der x86-Assemblerbefehl clflush, welcher eine Adresse entgegennimmt und die dazugehörige Cache-Line invalidiert, sodass die Daten beim nächsten Zugriff aus dem Hauptspeicher geladen werden müssen. TODO

\subsection{Prime + Probe}

Ein Eviction-Set sei eine Menge, welche es vermag einen Cache-Eintrag aus einem Cache zu verdrängen. D.h. ein Eviction-Set welches einen Eintrag aus dem L3-Cache löscht, würde den gleichen Zweck wie der clflush-Assemblerbefehl im Flush + Reload Angriff erfüllen. 
Um einen Eintrag aus dem Cache zu verdrängen, müssen mehrere Adressen der Daten aus dem Eviction-Set von der CPU auf die gleiche Cache-Set wie der zu verdrängende Eintrag abgebildet werden, sodass die Größe eines Eviction-Sets mindestens die Assoziativität des Caches erreichen sollte.

Die Idee beim Prime + Probe Angriff besteht darin, in einer sich wiederholenden Abfolge zuerst den Cache zu Primen, dann das Opferprogramm rechnen zu lassen und anschließend zu Proben.
In der Priming-Phase werden mittels der Eviction-Set gezielt Cache-Sets vollständig mit den Daten aus dem Eviction-Set belegt.
In der anschließenden Berechnungsphase werden einige Einträge aus den geprimten Cache-Sets vom Opferprogramm verdrängt. Abschließend berechnet die Angreiferin die Summe der Zugriffszeiten auf alle Einträge in einem Eviction-Set.
Sofern das Opferprogramm in dem zum Eviction-Set korrelierenden Cache-Set Einträge verdrängt hat, kann die Angreiferin eine Abweichung nach oben in ihrer Messung feststellen, da die verdrängten Einträge eine erhöhte Zugriffszeit beisteuern.

Die zur Durchführung essenziellen Eviction-Sets sind nicht immer leicht zu finden, da die virtuellen Adressen in manchen Umgebungen nur eingeschränkt zugänglich sind.
So lässt sich häufig nur garantieren, dass maximal die untersten 12 virtuellen Adressbits mit den physikalischen Adressenbits identisch sind, da die typische Page-Size 4096($2^12$) Bytes beträgt.
In solchen Fällen müssen die Eviction-Sets in einem Trial-and-Error Verfahren ermittelt werden, wie es der Algorithmus %\ref[alg:evictionSet}
beschreibt.

%Beschreibe Algorithmus
%Hierfür werden zuerst wiederholt Speicherblöcke angefordert, wobei solche in einer Menge gesammelt werden, welche 

\SetKwProg{Fn}{Function}{}{}

\begin{algorithm}[h]
\DontPrintSemicolon
\caption{Psuedo-Code für Eviction-Set Algorithmus}
\label{alg:evictionSet}

\Fn{$EvictionSetFinder(memoryBlocks)$}{
    groups \leftarrow empty\;
    \While{size(memoryBlocks > 0}{
        evictionSet $\leftarrow$ empty\;
		witness $\leftarrow$ expand(evictionSet, memoryBlocks)\;
		
		\If{witness != failed}{
    		contract(evictionSet, memoryBlocks, witness)\;
    		witnessSet $\leftarrow$ collect(evictionSet, memoryBlocks, witnessSet)\;
    		groups.add(union(evictionSet, witness, witnessSet))\;
		}
    }
}

\Fn{$Expand(evictionSet, memoryBlocks)$}{
	\While{size(candidateSet) > 0}{
		witnesss = SelectRandomItem(candidateSet)\;
		\If{checkevict(evictionSet, witnesss)}{
			\Return witnesss
		}
		evictionSet.add(witnesss)\;
	}
	\Return failed;
}

\Fn{$Contract(evictionSet, memoryBlocks, witness)$}{
	\ForEach{candidate in evictionSet}{
		\If{checkevict(evictionSet, witness)}{
			mermoryBlocks.add(candidate)\;
			evictionSet.add(candidate)\;	
		}		
	}
}

\Fn{$Collect(evictionSet, memoryBlocks)$}{
	witnessSet = empty\;
	\ForEach{candidate in mermoryBlocks}{
		\If{checkevict(evictionSet, candidate)}{
			memoryBlocks.delete(candidate)\;
			witnessSet.add(candidate)\;
		}
	}
	\Return witnessSet;
}

\end{algorithm}

\subsection{RSA}

Falls RSA angegriffen wird TODO

RSA Key Gen, RSA Verschlüsselung Entschlüsselung

