\chapter{Identifikation von Angriffszielen}
\label{chapter:results}

\section{RSA Key Generierung}

Frühere Arbeiten zu Cache-Angriffen hatten es vor allem auf die Verschlüsselung- und Entschlüsselungsroutinen der RSA-Implementierungen abgesehen \cite{FlushReload, CacheBleedOpenSSLRSA}, weshalb bei der Implantation ebendieser die Möglichkeit von Seitenkanalangriffen besonders im Hinterkopf behalten wird.
Ein anderen weniger untersuchten Einstiegspunkt für die Schlüsselextraktion bieten die Routinen zur Schlüsselgenerierung, welche in den letzten Monaten etwa in \cite{RSAKeyGeneration2} näher untersucht wurden.

\subsection{Primzahlgenerierung in Mozilla NSS}

Mozilla Network Security Services(NSS) ist ein Menge von Bibliotheken, welche eine plattformübergreifende Entwicklung von sicheren Client- und Server-Anwendungen anstrebt. Dabei wird unter anderem TLS oder S/MIME implementiert. Mozilla NSS wird etwa im Firefox-Browser und der Mail-Anwendung Thunderbird eingesetzt.
Der Quellcode ist unter der Mozilla Public License verfügbar und kann online etwa im Firefox-Repository \cite{MozillaDXR} eingesehen werden.

Um einen neuen Schlüssel zu erzeugen werden zuerst zwei Primzahlen generiert. 
Im Folgenden soll die Primzahlgenerierung von Mozilla NSS näher beleuchtet werden.
Der Code hierfür befindet sich im Unterordner lib/freebl.
Der Einstiegspunkt für die Primezahlgenerierung ist die Funktion generate_prime in der Datei rsa.c \ref{alg:genPrimeGenerationNSS}.
Dort wird zuerst eine ungerade Zufallszahl $random\_num$ entsprechend der Bitlänge der gewünschten Primzahl erzeugt, deren zwei höherwertigsten Bits auf 1 gesetzt sind.
Anschließend wird versucht auf Basis von $random\_num$ eine Primzahl zu erzeugen und diese im Erfolgsfall zurückgegeben.
Falls dies fehlschlägt wird der gesamte Vorgang bis zu 10 mal wiederholt bis die Primzahlgenerierung endgültig abgebrochen wird.

\begin{algorithm}[h]
\DontPrintSemicolon
\caption{Pseudo-Code für generate_prime in Mozilla NSS}
\label{alg:genPrimeGenerationNSS}

\Fn{$generate_prime(primeLen)$}{
    \For{1 to 10}{
        random\_num <- RNG_GenerateGlobalRandomBytes(primeLen)\;
        random\_num[0] |= 0xC0            /* set two high-order bits */\;
        random\_num[primeLen - 1] |= 0x01 /* set low-order bit       */\;
        successful <- mpp_make_prime(random\_num, \&prime)\;
        \If{successful}{
            \Return prime\;
        }
    }
    \Return no prime found
}
\end{algorithm}

Die Zahl $random\_num$ wird an die Funktion mpp_make_prime in der Datei mpprime.c übergeben \ref{alg:makePrimeGenerationNSS}.
Global definiert ist das Array $primes_tab$, das alle Primzahlen von 3 bis 2^16 beinhaltet. Dieses Array wird nicht dynamisch beim Start erzeugt, stattdessen stehen alle benötigten Primzahlen fix im Quellcode. 
Das Array $primes_tab$ wird im folgenden Siebvorgang benötigt, um mit wenig Rechenleistung eine Reihe von Primzahlkandidaten auszuschließen.
Dieser Siebvorgang wird in der Funktion mpp_sieve, ebenfalls in mpprime.c zu finden, definiert \ref{alg:sievePrimeGenerationNSS}.
Zahlen der Form $random\_num + 2 \cdot i$, mit $i \in [1\twodots SIEVE\_SIZE]$ sind mögliche Primzahlkandidaten.
Die später verwendeten Fermat- und Miller-Rabin-Tests sind relativ aufwendig, weswegen ein Siebvorgang analog zum Sieb des Eratosthenes vorangestellt wird.
Im Siebvorgang wird über alle Primzahlen im $primes_tab$-Array iteriert und jeweils der Rest $rem$ von $random\_num$$\mod$$small\_prime$ errechnet.

Durch den Aufruf von $mp_mod_d$ im Pseudocode in Zeile 4 wird angedeutet, dass diese Modulo-Operation nicht in einen einzigen Maschinenbefehl übersetzt werden kann, da die Zahl random\_num nicht in ein Register passt. Anders hingegen ist dies bei der Modulo-Operation in Zeile 10, da dort sowohl $i$ als auch 2 in ein Register passen.

Nun müssen zwei Fälle unterschieden werden:
Im ersten Fall sei $random\_num$ durch $small\_prime$ teilbar, das heißt $random\_num$$\mod$$small\_prime = 0$.
Dann ist $random\_num$ zusammengesetzt, sowie auch alle $random\_num + k \cdot small\_prime$ mit $k \in \mathbb{N}$.
Das $sieve$-Array dient später um die Primzahlkandidaten der Form $random\_num + 2 \cdot i$ mit $i \in [1\twodots SIEVE\_SIZE]$ zu erzeugen, wobei Kandidat $i$ nicht weiter betrachtet wird, wenn $sieve[i]$ auf $1$ gesetzt ist.

Im ersten Fall muss also $sieve[0] = 1$ gesetzt werden, da $random\_num \mod small\_prime = 0$.
Dies wird in der ersten Iteration der For-Schleife in Zeile 9 umgesetzt.
Außerdem muss $sieve[j] = 1$ gesetzt werden, falls $j = k \cdot small\_prime / 2$ gilt, da wie oben festgestellt $random\_num + k \cdot small\_prime$ bzw. $random\_num + 2 \cdot j$ zusammengesetzt ist.
Jenes wird in den restlichen Iterationen der For-Schleife umgesetzt, wobei Einträge im $sieve$-Array nur gesetzt werden, wenn $k \cdot small\_prime$ gerade ist.
Ungearde $k \cdot small\_prime$ sind uninteressant, da $random\_num$ ebenfalls ungerade ist und somit $random\_num + k \cdot small\_prime$ immer mindestens durch $2$ teilbar ist.

Im zweiten Fall sei $random\_num$ nicht durch $small\_prime$ teilbar, das heißt $rem \neq 0$.
Dann ist die Zahl $random\_num + (small\_prime - rem)$ durch $small\_prime$ teilbar, da $random\_num + (small\_prime - rem) \mod small\_prime = (random\_num \mod small\_prime + (small\_prime - rem)) \mod small\_prime = (rem + (small\_prime - rem)) = 0$.

Deshalb wird in der ersten Iteration der For-Schleife in Zeile 9 $sieve[(small\_prime - rem)/2] = 1$ gesetzt, unter der Bedingung das $(small\_prime - rem)/2$ gerade ist.
Zudem sind alle $random\_num + (small\_prime - rem) + k \cdot small\_prime$ durch $small\_prime$ teilbar, womit analog zu Fall 1 alle $sieve[j] = 1$ gesetzt werden, falls $j = ((small\_prime - rem) + k \cdot small\_prime) / 2$ ist.



\begin{algorithm}[h]
\DontPrintSemicolon
\caption{Pseudo-Code für mpp_sieve in Mozilla NSS}
\label{alg:sievePrimeGenerationNSS}
\Fn{$mpp\_sieve(random\_num, primes_tab, size)$}{
    
    \For{ix = 0; ix < nPrimes; ix++} {
        small\_prime <- primes_tab[ix]\;
        rem <- mp_mod_d(random\_num, small\_prime)\;

        \If{rem == 0}{
            offset = 0\;
        } 
        \Else {
            offset = small\_prime - rem\;
        }

        \For{i = offset; i < nSieve * 2; i += prime}{
            \If{i mod 2 == 0}{
                sieve[i / 2] = 1\;
            }
        }
    }
}
\end{algorithm}

Nachdem der Siebvorgang abgeschlossen ist, wird das $sieve$-Array in der Foreach-Schleife in Zeile 6 der Funktion mpp_make_prime verwendet.
Wie eben beschrieben können Kandidaten der Form $random\_num + 2 \cdot i$ ausgeschlossen werden, wenn $sieve[i] = 1$ gesetzt ist.
Die restlichen Kandidaten werden mittels des Fermat- und Miller-Rabin-Tests auf Primzahleigenschaft hin überprüft.
Werden auch diese Tests bestanden, wird die Zahl als Primzahl eingestuft und zurückgegeben.

\begin{algorithm}[h]
\DontPrintSemicolon
\caption{Pseudo-Code für mpp_make_prime in Mozilla NSS}
\label{alg:makePrimeGenerationNSS}
primes_tab <- [2, 3, 5, 7, ..., 65521] // 6541 primes from 3 to 2^16\;
SIEVE_SIZE <- 32 * 1024\;

\Fn{$mpp\_make\_prime(random\_num)$}{
    num_miller_rabin_tests <- get_num_tests(bitlen(random\_num)) // augmented by FIPS-186 requirements, Table C.2 and C.3

    sieve <- mpp_sieve(random\_num, prime_tab, SIEVE_SIZE)\;
    \ForEach{i in SIEVE_SIZE}{
        \If{sieve[i]}{ /*number is composite*/\;
            continue\;
        }
        probablePrime <- random\_num + 2*i\;
        \If{!mpp_fermat(probablePrime, 2)}{ //Fermat test with 2
            continue\;
        }
        \If{!mpp_pprime(probablePrime, num_tests)}{ //Miller Rabin test
            continue;
        }
        \Return probablePrime
    }
}
\end{algorithm}

\subsection{Primzahlgenerierung in OpenPGP.js}

OpenPGP ist ein Standard für das Signieren, Ver- und Entschlüsseln von Daten, welcher im RFC 4880 \cite{rfc4880} definiert wird.
OpenPGP.js \cite{OpenPGPjs} ist eine Opensource-Implementierung des OpenPGP-Protokolls in Javascript, welche sich zum Ziel gesetzt hat OpenPGP auf einer breiten Platte von Endgeräten zu ermöglichen.

Die Primzahlgenerierung von OpenPGP.js ist in der Datei prime.js beschrieben und startet mit der Funktion randomProbablePrime.
Zuerst wird eine Zufallszahl entsprechend der gewünschten Bitlänge generiert.
In OpenPGP.js wird kein Siebverfahren wie in Mozilla NSS angewandt, sondern es wird sichergestellt das ausschließlich nicht durch 2,3 und 5 teilbare Zahlen als Primzahlkandidaten weitergehend geprüft werden.
Dazu wird eine Zahl $n \mod 30$ berechnet und der Rest betrachtet.
Ist dieser weder durch 2,3 oder 5 teilbar so ist auch $n$ nicht durch 2,3 oder 5 teilbar.
Andernfalls wird die kleinstmögliche Zahl $k \in \mathbb{N}$ auf $n$ addiert, sodass $n + k \mod 30$ nicht durch 2,3 oder 5 teilbar ist.
Diese kleinstmögliche Zahl ist $adds[n \mod 30]$, das heißt beispielsweise ist $125$ zu $adds[125 \mod 30] = 2$ addiert gleich 127, die kleinstmögliche Zahl größer 125, welche nicht durch 2,3 und 5 teilbar ist.

Mit dieser Methode wird in der Zeile ein Kandidat erzeugt, der nicht durch 2,3 oder 5 teilbar ist und in der Funktion isProbablePrime tiefergehend geprüft wird.
Zuerst wird die Teilerfremdheit von $random\_num -1$ zu dem Exponenten $e$ überprüft (näheres dazu in \ref{RSAGenGCDAttack}).
Danach wird ein einfacher Divisiontest mit alle Primzahlen zwischen 7 und 5000 durchgeführt, wohingegen dieser in Mozilla NSS bereits durch den Siebvorgang abgedeckt ist.
Abschließend wird wie in Mozilla NSS ein Fermat- und Miller-Rabin-Test durchgeführt.

\begin{algorithm}[h]
\DontPrintSemicolon
\caption{Pseudo-Code für Primzahlgenerierung in OpenPGP.js}
\label{alg:randomProbablePrimeOpenPGPjs}
num_miller_rabin_tests <- get_num_tests(bitlen(random\_num))\;
small\_primes <- [7, 11, 13, 17, ..., 4999] //665 primes from 7 to 5000\;

\Fn{$randomProbablePrime(bits, e)$}{
    adds <- [1, 6, 5, 4, 3, 2, 1, 4, 3, 2, 1, 2, 1, 4, 3, 2, 1, 2, 1, 4, 3, 2, 1, 6, 5, 4, 3, 2, 1, 2]\;
    random\_num <- random.getRandomBN\;
    i <- random\_num mod 30\;
    
    \Repeat{!isProbablePrime(random\_num,e,num_miller_rabin_tests)}{
        random\_num <- random\_num + adds[i]\;
        i <- (i + adds[i]) mod 30\;
        // If reached the maximum, go back to the minimum.\;
        \If{bitlen(random\_num) > bits}{
            random\_num <- (random\_num mod $2^{bits}$) + $2^{bits-1}$\;
            i <- random\_num mod 30\;
        }
    }
}

\Fn{$isProbablePrime(random\_num, e, num\_miller\_rabin\_tests)$}{
    \If{gcd(random\_num-1, e) $\neq$ 1}{
        \Return false\;
    }
    \ForEach{small\_prime in small\_primes}{
        \If{random\_num mod small\_prime = 0}{
            \Return false\;
        }
    }
    \If{!fermat(random\_num, 2)}{
        \Return false\;
    }
    \If{!millerRabin(random\_num, k)}{
        \Return false\;
    }
    \Return true
}
\end{algorithm}

\subsection{Mögliche Leakage in Mozilla NSS}
\label{leakageMozillaNSS}

Das Ziel ist es die Zahl $random\_num$ oder Teile davon zu rekonstruieren.
Der Siebvorgang sticht hier besonders hervor, da dort unabhängig von $random\_num$ genau 6541 (Anzahl der Primzahlen von 3 bis $2^{16}$) Modulo-Operationen mit vorher bekannten Primzahlen auf $random\_num$ ausgeführt werden.

Typische RSA-Schlüssel besitzen heute eine Länge von 2048 Bit, sodass $random\_num$ etwa ein Länge von 1024 Bit besitzt.
Deswegen dauert die Berechnung von $random\_num \mod small\_prime$ im Schnitt TODO Taktzyklen.
Somit ist bekannt, dass auf das $primes\_tab$-Array nur jede TODO Taktzyklen einmal zugegriffen wird.

Das $primes\_tab$-Array ist vom Datentyp mp_digit, der bei einer Linux x64-Kompilierung gleichbedeutend mit ein 8 Byte Integer ist.
Somit hat das $primes_tab$-Array ein Gesamtgröße von $8 \cdot 6541 = 52328 Bytes$ und liegt in $\lceil 52328 / 64 \rceil = 818$ verschiedenen Cache-Lines bzw. $\lceil 52328 / 4096 \rceil = 13$ Pages.

Angenommen die zu primes_tab[0-7] gehörige Cache-Line wird mittels Prime-and-Probe überwacht, dann können nach Start des Siebvorgangs 8 Zugriffe mit jeweils etwa TODO Taktzyklen Abstand gemessen werden.
Nachdem 8. Zugriff muss die überwachte Cache-Line auf $primes\_tab[8-15]$ für weitere 8 Zugriffe gewechselt werden usw.

Um die notwendigen Cache-Sets zu Finden muss nur jeweils ein Cache-Set pro 4-KiB Page identifiziert werden, da wie bereits erwähnt die Adressen innerhalb einer Page identisch sind.
Das Zugriffsmuster auf jede Cache-Lines des $primes\_tab$-Array entspricht immer 8 Zugriffen mit jeweils TODO Taktzyklen Pause. Außerdem liegt das $primes\_tab$-Array immer an der selben Adresse im Speicher.
Die Angreiferin kann selber Schlüsselgenerierungen anstoßen, sodass es ihr möglich ist die passenden Eviction-Sets für das $primes\_tab$-Array zu finden.

Die Schreibzugriff auf das $sieve$-Array in der For-Schleife (siehe \ref{alg:sievePrimeGenerationNSS} Zeile 9-11) sind mit einer Laufzeit von etwa 100 Taktzyklen zu schnell um einzelne Zugriffe unterscheiden zu können.
Das $sieve$-Array ist ein Byte Array der Größe 32768 Bytes und liegt somit in 512 Cache-Lines.
Bei den ersten Iterationen der For-Schleife mit kleinen Primzahlen wie der 3 wird noch auf alle 512 Cache-Lines zugegriffen.
Sobald die Primzahlen aber den Wert 64 überschreiten werden Cache-Sets ausgelassen.

Zur Veranschaulichung hier ein Beispiel:

Angenommen $random\_num \mod 67 = 0$ und die For-Schleife der Zeile 9-11 ist in der 42. Iteration, das heißt $i=2814$ ist gerade.
Dann wird gemäß Zeile 11 $sieve[1407] = 1$ gesetzt, hiermit auf die Cache-Line für $sieve[1344-1407]$ zugegriffen und abschließend $i=2881$ gesetzt.

In der 43. Iteration wird auf keine Cache-Line von $sieve$ zugegriffen, da $i=2881$ ungerade ist.

Die 44. Iteration arbeitet mit $i=2948$ und setzt somit den Wert $sieve[1474] = 1$.
Die zugehörige Cache-Line ist nun $sieve[1472-1535]$, womit keinerlei Zugriff auf die Cache-Line $sieve[1408-1471]$ erfolgt.

Im Gegensatz zum $primes\_tab$-Array wird das $sieve$-Array dynamisch in der Funktion erzeugt, also kann die Angreiferin dies nicht durch vorherige Schlüsselgenerierungen lokalisieren.
Ihr ist aber bekannt, dass solange $small\_prime$ < 64 (17 Primzahlen) ist auf alle Cache-Lines des $sieve$-Arrays zugegriffen wird.

Durch eine gleiche Änderung der letzten 12 Bits der Adressen eines bestehenden Eviction-Set entsteht ein neues gültiges Eviction-Set, welches im Folgenden als benachbartes Eviction-Set bezeichnet wird.

Das $sieve$-Array in 512 Cache-Lines aufgeteilt ist, zwischen den Zugriffen auf das $sieve$-Array ist eine Pause von TODO Taktzyklen, aber die eigentliche Aktivität auf dem $sieve$-Array ist mit unter 100 Taktzyklen pro Iteration vergleichsweise kurz.
Daher muss die Angreiferin nach dem Zugriff auf das $primes\_tab$-Array eine Reihe von Eviction-Sets primen, warten bis auf das $primes\_tab$-Array erneut zugegriffen wird und dann proben.

Sofern ein Eviction-Set in dieser Phase Aktivität gezeigt hat, werden in der nächsten Iteration seine benachbarten Sets überwacht.
Denn wenn das Eviction-Set eine Cache-Line des $sieve$-Array verdrängt hat, so müssen auch die benachbarten Eviction-Sets in der nächsten Runde Aktivität auf ihrer zugehörigen Cache-Line zeigen.
So können die relevanten Eviction-Set schnell eingegrenzt werden, da initial maximal 128 Eviction-Set in Frage kommen.
Die restlichen 8064 Eviction-Sets sind zu diesen 128 benachbart, müssen also nicht initial überwacht werden.

Cache-Lines im $sieve$-Array auf die nicht zugegriffen wird können Informationen preisgeben, da das $i$ der For-Schleife in Abhängigkeit der Berechnung $random\_num \mod small\_prime$ definiert wird.

Dies soll an folgendem Beispiel verdeutlicht werden:

Angenommen es wurde ein Zugriff auf die Cache-Line $sieve[64-127]$, aber nicht auf die Cache-Line $sieve[0-63]$ gemessen und $small\_prime$ ist für die aktuelle Iteration bekannt. Festzuhalten ist, dass $i \in \{128,...,254\}$ und gerade sein muss, sodass ein Schreibzugriff auf $sieve[64-127]$ in Zeile 11 ausgeführt wird.
Weiter kann nicht $random\_num \mod small\_prime = 0$ gelten, da ansonsten ein Zugriff auf die Cache-Line $sieve[0-63]$ messbar wäre. 
Es wird nun zwischen verschiedenen Werten für die Variable offset (siehe Zeile 6 und 8 in mpp_sieve) unterschieden.

1. Fall: Sei $offset \in [128\twodots254]$ und gerade, also $offset \mod 2 = 0$. 

Dann ist $rem = small\_prime - offset$ und durch die Kenntnis von $small\_prime$ und $offset \in [128\twodots254]$ gerade kann $rem$ auf 64 mögliche Werte eingegrenzt werden.

2. Fall: Sei $offset$ ungerade, also $offset \mod 2 = 1$ und $offset_ex = offset + small\_prime \in [128\twodots254]$ und $offset_ex \mod 2 = 0$. Da $i=offset$ und $offset$ ungerade erfolgt in der ersten Iteration der For-Schleife kein Zugriff auf das $sieve$-Array. Wenn der Zugriff also in der zweiten Iteration erfolgt ist $i = offset + small\_prime = offset\_ex$.

Da $offset = offset\_ex - small\_prime$ ist $rem = small\_prime - (offset\_ex - small\_prime) = 2 \cdot small\_prime - offset\_ex$ und durch die Kenntnis von $small\_prime$ und $offset\_ex \in [128\twodots254]$ gerade kann $rem$ auf 64 mögliche Werte eingegrenzt werden.

Es ist unbekannt ob $rem$ gerade oder ungerade ist, weshalb $rem$ nicht weiter als auf 128 mögliche Werte eingegrenzt werden kann.

Mit dieser Leakage ergeben sich "unscharfe" Kongurrenzen bezüglich des Wertes $random\_num$ der folgenden Form:
\begin{align}
    random\_num \mod small\_prime \equiv a &\text{ mit } a \in A
\end{align}
a kann durch diese Leakage nicht exakt bestimmt werden, deshalb ist $A_i$ die Menge mit den möglichen Werten die a annehmen kann.
Im oberen Beispiel gilt etwa $|A_i| = 128$ und $\{128,130,132,...,254\} \subsetneq A_i$, wobei die andere 64 Einträge von $A_i$ durch $small\_prime$ definiert werden.

Mit dieser Beobachtung kann für $random\_num$ folgendes Gleichungssystem definiert werden:
\begin{align*}
    random\_num \mod small\_prime_i &\equiv a_i &\text{ mit } a_i \in A_i\\
    random\_num \mod \prod_i small\_prime_i &< 2^{bits+1} \\
    random\_num \mod \prod_i small\_prime_i &> 2^{bits}
\end{align*}
$A_i$ ist hier analog zu oben die Menge der möglichen Werte für $random\_num \mod small\_prime_i$ die durch die Leakage bekannt werden.
Um den Lösungsraum dieses Gleichungssystems einzuschränken, wird die Tatsache genutzt, dass $2^{bits} < random\_num < 2^{bits+1}$.

Angenommen jedes $a_i$ wäre eindeutig, das heißt $|A_i|=1$, dann existiert gemäß dem Chinesischen Restsatz \ref{chinese_remainder} genau eine Lösung im Bereich von $0$ bis $\prod_i small\_prime_i$.
Weiter sei $bitlen(small\_prime_i) > 10 \: \forall i$, dann würden $bitlen(random\_num)/10$ Gleichungen ausreichen, um $random\_num$ eindeutig zu bestimmen.
Jede Gleichung bringt also in etwa 10 Bit an Information über $random\_num$.

Im Fall der oben beschrieben Leakage, bringt eine Gleichung aber 7 Bit oder 128 mögliche Werte als Unsicherheit mit.
Angenommen es existieren 1000 Gleichungen mit $bitlen(small\_prime_i) > 10 \: \forall i$, sodass es $2^{7000}$ mögliche Lösungen gibt und diese im Bereich 0 und $2^{10000}$ liegen.
Da $2^{bits} < random\_num < 2^{bits+1}$ gilt und die möglichen Lösungen über den gesamten Lösungsraum verstreut sind, ist die Wahrscheinlichkeit hoch eine eindeutige Lösung für $random\_num$ zu finden.

Dem Autor ist allerdings unklar wie schwer eine Lösung für dieses Problems ist.
Sofern erlaubt ist, dass die Moduli $small\_prime_i$ beliebige Werte annehmen könnten, ist das Problem beweisbar NP-schwer \cite{FuzzyCRTProof}.
Ein wesentliche Voraussetzung für die Beweisidee ist hier die beliebigen Werte für die Moduli, sodass eine Adaption der Beweisidee an das ursprüngliche Problem nicht möglich scheint.

Auch wenn das Problem NP-schwer sein sollte, schließt dies nicht automatisch eine schnelle Lösung für bestimme Instanzen des Problems aus.
So lässt sich das Problem etwa als Integer Programming Problem (ILP) formulieren:
Ein Constraint ist die Einschränkung von $random\_num$ in den Bereich von $2^{bits}$ bis $2^{bits+1}$.
Und jede Modulo-Gleichung $x \equiv a \mod m$ wird zu $x + f \cdot m = a$ übersetzt.

Typische ILP-Solver wie etwa LP-Solve arbeiten aber nicht mit großen Ganzzahlen, sodass als Lösung wegfallen.
In Mathematica lässt sich das Problem beschreiben, jedoch wurde der Versuch kleine Probleminstanzen mit $random\_num \approx 2^100$ zu lösen nach mehreren Stunden abgebrochen.
Durch das Laufzeitverhalten lässt sich vermuten, dass Mathematica den langsamen und trivialen Ansatz verfolgt alle Lösungsmöglichkeiten durchzuprobieren.

Die Fallunterscheidung in der Funktion mpp_sieve in den Zeilen 5 bis 8 würde die Information liefern ob $random\_num \mod small\_prime = 0$ ist.
Unabhängig von $rem$ wird aber immer der gesamte Assemblercode für die Zeilen 5 bis 8 geladen \ref{fig:assemblyMppSieve}, da die Vergleichsoperation an Adresse 806A4 und der Code für die folgende For-Schleife an der Adresse 806CA immer benötigt wird.
Der Abstand zwischen den Adressen 806A4 und 806CA ist kleiner als die Größe einer 64 Byte Cache-Line, das heißt die vorherige Aussage ist losgelöst von den Adressen des Codes in der Binary.
Somit ist ein Prime-and-Probe Angriff auf den entsprechenden Codeteil nicht möglich, da sofern der Assemblercode für die Zeile 5 bis 8 in zwei Cache-Lines fällt immer bei beiden eine erhöhte Zugriffszeit gemessen würde.

\begin{figure}[h]
\label{fig:assemblyMppSieve}
\renewcommand\fcolorbox[4][]{\textcolor{black}{\strut#4}}
\small
%00000000000806A4 <For-Schleife Zeile 5 bis 8>:
\begin{minted}{gas}
  806A4:        cmp    [rem], 0
  806AA:        jnz    else
  806AC:        mov    [offset], 0  
  806B4:        jmp    next_code
  806B6: else:  mov    rax, [rem]
  806BB:        mov    rcx, [small\_prime]
  806C0:        sub    rcx, rax
  806C3:        mov    rax, rcx
  806C6:        mov    [offset], eax
  806CA: //Code for line 9
\end{minted}
\normalsize
\caption{Assemblercode für die Zeilen 5 bis 8 der Funktion mpp_sieve}
\end{figure}

\subsection{Mögliche Leakage in OpenPGP.js}

Auch hier ist der Siebvorgang ein möglicher Teil, um Informationen über $random\_num$ zu gewinnen.
Ansatzpunkt ist wie im letzten Abschnitt die Überwachung des $small\_primes$-Arrays, wobei Chrome auf dem verwendeten Testsystem 8 Byte für jeden Eintrag verwendet. Javascript legt die Größe des Datentyps für das $small\_primes$-Array nicht fest, weshalb diese Aussage nicht auf andere Systemkonfigurationen zutreffen muss.

Der Wert $random\_num$ wird nach jedem Abbruch der Funktion $isProbablePrime$ um einen bestimmten Wert inkrementiert.
Sei $random\_num_k$ der Wert $random\_num$ in dem $k.$-Durchlauf der Schleife in den Zeilen 7 bis 14.

Es werden also pro Cache-Line, welche 8 Einträge des $small\_primes$-Array abdeckt, bis zu 8 Zugriffe erwartet im Abstand von der Dauer einer Modulo-Operation, hier im Mittel etwa 1600 Taktzyklen, erwartet.
In der Cache-Line mit weniger als 8 Zugriffen gilt für einen der $small\_prime_i$-Werte $random\_num_k \mod small\_prime_i = 0$, wobei dies zu einem sofortigen Abbruch (siehe Zeile 20) führt.
Folglich haben wir die Information $random\_num_k \mod small\_prime_i = 0$, aber auch $random\_num_k \mod small\_prime_j \neq 0 \: \forall j < i$.
Um sicherzugehen, dass die Foreach-Schleife in Zeile 18 vorzeitig verlassen wurde, kann zusätzlich der Code der Zeilen 7 bis 14 überwacht werden, welcher nach einem Abbruch geladen wird.

Da sich $random\_num$ in jeder Schleifen-Iteration ändert, müssen die aus der $isProbablePrime$-Funktion für $random\_num_k$ gewonnen (Un)gleichungen  angepasst werden.

Die Differenz von $random\_num_k$ und $random\_num_{k+1}$ ist mit dem maximalen Wert im $adds$-Array, also 6 gleichzusetzen.
Somit könnten aus den Beobachtungen Gleichungen folgender Form aufgestellt werden:
\begin{align*}
    (random\_num + b) \mod small\_prime_j \not\equiv 0 &\text{ mit } b \in [k\twodots6k] \text{ und } j < i\\
    (random\_num + b) \mod small\_prime_i \equiv 0 &\text{ mit } b \in [k\twodots6k]
\end{align*}

Es steht die Frage im Raum wie viele Gleichungen für die vollständige Rekonstruktion einer Primzahl benötigt werden.
Für den Informationsgehalt der zweiten Gleichung ist die mittlere Größe von $small\_prime_i$ ausschlaggebend.
Tabelle \ref{} zeigt die erwartenden Werte für verschiedene Primezahlbitlängen. 
\todo{prüfen wie sich verhalten mit unterschiedlichen bitlängen verändert}

Angenommen $small\_prime_i$ hat im Mittel eine Bitlänge von $l$, dann liefert die zweite Gleichung $l$ Bit an Information über (random\_num + b).
Allerdings erhöht sich durch $b$ die Anzahl der möglichen Lösungen mit jeder Gleichung um den Faktor 6.
Analog zu den Betrachtungen im Abschnitt \ref{leakageMozillaNSS} kann jedoch die Zusatzinformation $2^{bits} < random\_num < 2^{bits+1}$ herangezogen werden, um den Lösungsraum einzuschränken.
Somit gibt es bei $t$-Gleichungen $6^t$ mögliche Lösungen, welche sich auf das Intervall $[0 \twodots2^{l\cdot t}]$ verteilen, wobei nur Lösungen im Intervall $[2^{bits} \twodots 2^{bits+1}]$ valide sind.
Wenn $t > \lceil bits/10 \rceil$ gilt, dann ist $6^t/2^{l \cdot t} \cdot 2^{bits}$ eine Abschätzung wie viele der möglichen Lösungen im Mittel im validen Intervall $[2^{bits} \twodots 2^{bits+1}]$ landen.

Es bleibt zu klären wie viele der Gleichungen des 2. Typs erwartet werden können oder anders ausgedrückt wie viele Zahlen müssen im Mittel getestet werden bis eine die Primzahltests besteht. 
Für eine Abschätzung der zu erwartenden Anzahl sei angenommen, dass die Funktion ausschließlich Primzahlen zurückgibt, sodass der Primzahlsatz herangezogen werden kann, um die Anzahl der Primzahlen abzuschätzen.
Ist beispielsweise eine 1024 Bit Primzahl gewünscht, so wird aus dem Intervall $[2^{bits}\twodots 2^{bits+1}-1]$ eine der \begin{align}
\pi(2^{1025}-1) - \pi(2^{1024}) = \frac{(2^{1025}-1)}{\ln(2^{1025}-1)} - \frac{2^{1024}}{ln(2^{1024})} \approx 2^{1014,53}
\end{align}
möglichen Primzahlen gewählt.
Somit ist im Intervall $[2^{1024}\twodots 2^{1024+1}-1]$ etwa eine von $2^{1024}/2^{1014,53} \approx 711$ Zahlen eine Primzahl.
Da durch 2,3 und 5 teilbare Zahlen nicht getestet werden, entfallen $22/30$ aller natürlicher Zahlen als Testkandidaten.
Folglich ist bei einer Bitlänge von 1024 jede $711 \cdot 8/30 \approx 190$ getestete Zahl eine Primzahl, sodass ausgehend von einer zufälligen Zahl im Intervall $[2^{1024}\twodots 2^{1024+1}-1]$ im Mittel etwa 95 Iterationen zum Fund einer Primzahl ausreichen.

Die im Mittel benötigte Anzahl skaliert linear mit der Bitlänge, die Übersichtstabelle \ref{tbl:bitLengthNumberOfIterations} gibt den Erwartungswert für verschiedene Bitlängen an.
\begin{table}[h]
\label{tbl:bitLengthNumberOfIterations}
\caption{Veranschaulicht den linearen Zusammenhang zwischen dem Erwartungswert für die Anzahl der Iterationen in Funktion $randomProbablePrime$ (siehe Pseudocode \ref{alg:randomProbablePrimeOpenPGPjs}) bei verschiedenen Primzahlbitlängen.}
\begin{tabular}{lllll}
Bitlänge Primzahl     & 1024 & 1536 & 2048 & 4096 \\
E(Anzahl Iterationen) & 95   & 142  & 189  & 379 
\end{tabular}
\end{table}

Um die Unsicherheit der obigen Gleichungen zu verringern soll im Folgenden das $adds$-Array näher analysiert werden.
Dieses benötigt im Chrome 8 Byte pro Dateneintrag und ist somit über 4 Cache-Lines mit folgenden Werten verstreut:\\
Cache-Line 1: 1, 6, 5, 4, 3, 2, 1, 4\\
Cache-Line 2: 3, 2, 1, 2, 1, 4, 3, 2\\
Cache-Line 3: 1, 2, 1, 4, 3, 2, 1, 6\\
Cache-Line 4: 5, 4, 3, 2, 1, 2

Wenn etwa bekannt ist, das der $adds$-Array Zugriff in Zeile 8 der Schleife eine Aktivität in Cache-Line 2 ausgelöst hat, so war $adds[i] \in \{1,2,3,4\}$, sodass die Möglichkeiten 5 und 6 ausgeschlossen werden können.
Somit kann der Offset-Wert $b$ bei Kenntnis von Eviction-Sets zu den 4 Cache-Lines eingrenzt werden.

Problematisch ist jedoch die Definition des $adds$-Arrays innerhalb der Funktion \textit{randomProbablePrime}, da bei Versuchen mit Chrome das Array mit jedem Funktionsaufruf an einer anderen Stelle im Speicher stand.
Das $adds$-Array während der Laufzeit der $randomProbablePrime$-Funktion zu finden ist schwierig, da nur ein Zugriff in jeder der über 2000 Taktzyklen dauernden Schleifeniteration erfolgt.
Alle Eviction-Sets die eine Aktivität in diesem Zeitraum zeigen, müssten ebenso wie ihr direkt benachbartes Eviction-Set über mehrere Iterationen überwacht werden.
Wenn ein Eviciton-Set das initial gefunden wurde in einer der Folgeiteration keine Aktivität mehr misst, dann muss das direkt benachbarte Eviciton-Set Aktivität messen.

Erschwerend ist außerdem, dass die Schleife in den Zeilen 7 bis 14 im Mittel nur TODO mal ausgeführt wird und somit die Zugriffe auf das $adds$-Array nach oben begrenzt sind.

Wie bereits erwähnt optimieren moderne Browser häufig verwendete Codeteile während der Laufzeit.
Wenn die Angreiferin also häufig hintereinander eine Schlüsselgenerierung mit kleinstmöglicher Bitlänge anstößt, könnte dies den Browser dazu veranlassen die Funktion $randomProbablePrime$ zu optimieren. 
In diesem Zuge könnte das $adds$-Array dauerhaft außerhalb der Funktion vorgehalten werden, anstatt es bei jedem Funktionsaufruf dynamisch zu erzeugen.
Dann könnte die Angreiferin die zu den 4 Cache-Lines gehörigen Eviction-Sets bereits im Voraus suchen.
Mit der verwendeten Systemkonfiguration konnte ein solches Verhalten in Chrome nicht erzeugt werden.

Zusammenfassend lassen sich Gleichungen wie im Abschnitt \ref{leakageMozillaNSS} aufstellen, wobei dem Autor unklar ist wie schnell sich diese lösen lassen.

\section{Zusätzliche Schlüsselprüfungen in Mozilla NSS}
\label{RSAGenGCDAttack}

Ein wichtige Eigenschaft ist, dass beide Primzahlen des Schlüssels teilerfremd zum Exponenten $e$ sind.
In Mozilla NSS werden zuerst die Schlüsselparameter $p,q,n,d,e$ bestimmt und anschließend in der Funktion RSA_PrivateKeyCheck auf Gültigkeit überprüft (siehe Pseudo-Code \ref{alg:RSA_PrivateKeyCheck}).

\begin{algorithm}[h]
\DontPrintSemicolon
\caption{Pseudo-Code für RSA_PrivateKeyCheck aus rsa.c}
\label{alg:RSA_PrivateKeyCheck}

\Fn{$RSA_PrivateKeyCheck(key)$}{
    assert(p $\neq$ q)\;
    assert(n == p * q)\;
    assert(gcd(e, p-1) == 1)\;
    assert(gcd(e, q-1) == 1)\;
    assert(d*e == 1 mod p-1)\;
    assert(d*e == 1 mod q-1)\;
    assert(d_p == d mod p-1)\;
    assert(d_q == d mod q-1)\;
    assert(q * q^-1 == 1 mod p)\;
}
\end{algorithm}

%Ausgehend von der Funktion RSA_NewKey in rsa.c

%\begin{algorithm}[h]
%\DontPrintSemicolon
%\caption{Pseudo-Code für RSA_NewKey aus rsa.c}
%\label{alg:mp_gcd}
%
%\Fn{$RSA_NewKey(keySizeInBits, e)$}{
%    p $rightarrow$ generate_prime(keySizeInBits)\;
%    q $rightarrow$ generate_prime(keySizeInBits)\;
%    d $rightarrow$ rsa_build_from_primes(p,q,e)\;
%}
%\end{algorithm}

Relvant für diese Arbeit sind im Wesentlichen die Zeilen 4 und 5, in denen die Teilerfremdheit von $e$ zu $p-1$ und $q-1$, d.h. $gcd(e,p-1) = 1$ und $gcd(e,q-1) = 1$ geprüft wird.
Aus Performancegründen wird der Exponent $e$, anders als ursprünglich im RSA-Algorithmus beschrieben, auf den Wert 65537 fixiert.

\subsection{Theoretische Leakage-Analyse}

Interessant ist die Funktion $mp_gcd$, welche den größten gemeinsamen Teiler nach dem binären Verfahren von Josef Strein \cite{SteinBinaryGCD} berechnet. 
Dieser Algorithmus (siehe Pseudocode \ref{alg:mp_gcd}) verwendet zum Berechnen des ggT ausschließlich Rechts-Shift-Operationen (Teilen durch 2) und Subtraktionen, wodurch dieser besonders für die in diesem Kontext verwendeten großen Zahlen interessant ist.
Die Zeilen 1 bis 6 der Funktion $mp\_gcd$ können in diesem Fall ignoriert werden, da der Exponent $e$ wie oben beschrieben immer 65537 und damit ungerade ist. 
Bedeutender hingegen ist die $while$-Schleife in den Zeilen 11 bis 17, welche abhängig von den Eingaben Fallunterscheidungen durchführt. 

\begin{algorithm}[h]
\DontPrintSemicolon
\caption{Pseudo-Code für mp_gcd nach Josef Stein}
\label{alg:mp_gcd}

\Fn{$mp_gcd(u,v)$}{
    k $\leftarrow$ 0\;
    \While{iseven(u) \& iseven(v)}{
        u $\leftarrow$ u/2\;
        v $\leftarrow$ v/2\;
        k++\;
    }

    \If{isodd(u)}{
        t $\leftarrow$ -v\;
    } \Else {
        t $\leftarrow$ v\;
    }

    \While{t $\neq$ 0}{
        \While{iseven(t)}{
            t $\leftarrow$ t/2\;
        }
        \If{t > 0} {
            u $\leftarrow$ t\;
        } else {
            v $\leftarrow$ -t\;
        }
        t $\leftarrow$ u - v\;
    }

    \Return u*2^k
}
\end{algorithm}

Die im Folgenden beschriebene Leakage geht auf die Veröffentlichung \cite{RSAKeyGeneration2} zurück in welcher die Autoren die binäre GCD-Implementation in OpenSSL untersucht haben.

Der Kontrollfluß der Funktion ist stark abhängig von den Eingaben und sorgt dafür, dass zwischen zwei Aufrufen der Subtraktionsfunktion (Zeile 17) unterschiedliche viele Rechts-Shift-Operation (Zeile 13) stattfinden.
Gemäß der der hierzu vorhandenen Literatur wird der Kontrollfluß des Algrotihmus mit 2 Symbolen beschrieben.
Dabei "L" steht für eine Rechts-Shift-Operation und "S" für eine Subtraktion.
Ein kompaktere Repräsentation verwendet die Variable $Z_i$ für die Anzahl der Rechts-Shift-Operationen in Iteration $i$.
Variable $X_i$ repräsentiert den binären Wert des Konditionals in Zeile 14 mit $X_i=t$ für $t>0$ und $X_i = f$ für $t \leq 0$.

Bei der folgenden Analyse wird ausgenutzt, dass der Wert $e=65535$ fix und bekannt, sowie deutlich kleiner als $p$ bzw. $q$ bei heute gängigen 1024 Bit Primzahlen ist.
Die Analyse soll sich im Folgenden exemplarisch auf $p$ beschränken.
Diese große Differenz zwischen $e$ und $p$ sorgt dafür, dass die Bedingung in Zeile 14 für fast alle Iterationen mit $X_i = f$ vorhergesagt werden kann.
Denn beim Aufruf der Funktion $mp_gcd$ gilt $u=e, v=p-1$ und da $u=e=65535$ ungerade ist gilt $t=-p+1$.
Beispielhaft wird nun die erste Iteration der Schleife in Zeile 11 bis 17 betrachtet.
Durch die Shift-Operation der Schleife in Zeile 12 und 13 wird $t=(-p+1)/2^{Z_1}$ gesetzt.
Es gilt $t<0$, daher wird $v=-t=(p-1)/2^{Z_1}$ gesetzt. 
Zum Abschluss der Iteration wird in der Subtraktion in Zeile 17 $t=u-v=e-(p-1)/2^{Z_1}$ gesetzt.

Somit gilt $t>0$ solange bis t ungefähr auf die Bitlänge 17 von $u=e$ geschrumpft ist.
Wenn die Subtraktionen von $e$ außeracht gelassen werden wird t etwa $\operatorname{ld}(p) - \operatorname{ld}(e)$ mal geteilt bevor der obige Fall eintritt.

Gemäß der Definition der $Z_i$ verliert $t$ in jeder Iteration $Z_i$ Bits. 
Die Anzahl der Iterationen $k$ der Schleife in den Zeilen 11 bis 17 bis $t$ die selbe Bitlänge wie $u$ erreicht, ist das kleinste $k$ welches folgende Gleichung erfüllt: 
\begin{align}
\label{equationN}
n = \sum\limits_i^k = Z_i >= \operatorname{ld}(p) - \operatorname{ld}(e)
\end{align}
Es stellt sich also die Frage, wie viele Bits in diesem Szenario rekonstruiert werden können.
Angenommen die Angreiferin erhält alle $Z_i$ bis zur Iteration $k$ in der das erste Mal $t<u=e$, das heißt $X_i=f \: \forall i < k$ gilt.
Sei $t_i$ der Wert von $t$ am Beginn der Iteration (Zeile 11) $i<t$, wobei $u_i=u_1=e$ für alle Iteartionen $i<t$ bleibt.
Es gilt 
\begin{align}
t_1=-p+1 \text{, } \: t_{i+1} = \frac{t_i - e}{2^{Z_{i+1}}}
\end{align}
Die Gleichung $u-v \equiv 0 \mod 2$ gilt für alle Iterationen, da $u$ und $v=-t$ am Ende der Iteration jeweils ungerade sind.
Aufgelöst gilt für $e-t_k$:
\begin{align}
e-t_k = e- \cfrac{-p+1}{e - \cfrac{2^{Z_1}}{e- \cfrac{2^{Z_2}}{
          \cfrac{2^Z_3}{e - \cfrac{\ddots}{2^{Z_k}}}}}} \equiv 0 \mod 2
\end{align}
Um Bits von $p$ zu erhalten, wird der obige Kettenbruch nach $p$ aufgelöst
\begin{align}
p = -e(2^Z_1+2^{Z_1+Z_2}+...+2^n)+1 \mod 2^{n+1}
\end{align}
, wobei $n$ die Anzahl der rekonstruierten Bits nach Gleichung \ref{equationN} angibt.
Zusammenfassend könnten etwa $bitlen(p)-bitlen(e)=bitlen(p)-17$ Bits rekonstruiert werden.
Mittels des Coppersmith-Angriffs \cite{CoppersmithBound} benötigt die Angreiferin jedoch nur die Hälfte der Bits der Primzahlen $p$ oder $q$ um den gesamten Schlüssel zu rekonstruieren.

\subsection{Praktische Leakage-Analyse}

Wie im vorherigen Abschnitt beschrieben muss die Angreiferin die Werte $Z_i$ bestimmen.
Hierzu bietet es sich an die Codefragmente zu überwachen, welche die Shift- bzw. Subtraktionfunktion ausführen.

In Mozilla NSS wird die Shift-Operation durch die Funktion $s\_mp\_div\_2$ umgesetzt.
Diese ist wiederum nur ein Wrapper und ruft intern die $s\_mp\_div\_2d$-Funktion mit dem Parameter 1 auf, welches dem Teilen durch 2^1 entspricht.
Die $s\_mp\_div\_2d$-Funktion setzt die Division mittels der $s\_mp\_rshd$-Funktion (Rechtsshift) um. 
Am Ende der $s\_mp\_div\_2d$-Funktion erfolgt ein Funktionsaufruf an $s\_mp\_clamp$ um die entstandenen führende Nullen zu entfernen.
Welche Adressen die Funktionen im Assemblercode haben, ist in Tabelle \ref{tbl:assOffsetShift} ersichtlich. 

\begin{table}[h]
\label{tbl:assOffsetShift}
\caption{Größe, Start- und Endadresse der für die Shift-Operation relevanten Funktionen (fett hervorgehoben) sowie deren direkten Nachbarn im Assemblercode.}
\begin{tabular}{llll}
Funktion       & Startadresse & Endadresse & Differenz (Größe der Funktion) \\[10pt]
s\_mp\_alloc   & b7d0$_{16}$        & b7f4$_{16}$      & 25$_{16}$   \\
s\_mp\_free    & b7f5$_{16}$        & b815$_{16}$      & 21$_{16}$   \\
\textbf{s\_mp\_clamp}   & b816$_{16}$        & b85e$_{16}$      & 49$_{16}$   \\
s\_mp\_exch    & b85f$_{16}$        & b8ce$_{16}$      & 70$_{16}$   \\
$\vdots$               &  $\vdots$             &    $\vdots$         &     $\vdots$   \\
s\_mp\_mul\_2d & b9c1$_{16}$        & bb76$_{16}$      & 1b6$_{16}$   \\
\textbf{s\_mp\_rshd}    & bb77$_{16}$        & bc5f$_{16}$      & e9$_{16}$   \\
\textbf{s\_mp\_div\_2}  & bc60$_{16}$        & bc7e$_{16}$      & 1f$_{16}$   \\
s\_mp\_mul\_2  & bc7f$_{16}$        & bd58$_{16}$      & da$_{16}$   \\
$\vdots$               &  $\vdots$             &    $\vdots$         &     $\vdots$   \\
s\_mp\_mod\_2d & bd59$_{16}$        & be16$_{16}$      & be$_{16}$   \\
\textbf{s\_mp\_div\_2d} & be17$_{16}$        & bf1d$_{16}$      & 107$_{16}$  \\
s\_mp\_norm    & bf1e$_{16}$        & bfde$_{16}$      & c1$_{16}$  
\end{tabular}
\end{table}

Eine Änderung innerhalb der Funktionen, welche die Größe beeinflusst ist bei diesen grundlegenden Funktionen unwahrscheinlich.
Bei Änderungen im Code außerhalb dieser Funktionen, werden sich alle Adressen um einen bestimmten Offset ändern.
Deshalb sind in der Tabelle die Größe der Funktionen im Assemblercode und deren direkten Nachbarn angegeben, um abzuschätzen welche weiteren Funktionen überwacht werden.
Die im weiteren Verlauf vorgenommene Bewertung der Funktionen hängt also auch von der Lage ebendieser im Assemblercode ab und kann bei Änderungen der Adressen variieren.

Es bestehen mehrere Möglichkeiten die Ausführung der Shfit-Operation zu erkennen, wobei sich manche im Callstack befindliche Funktionen weniger eigenen, da sie auch an anderer Stelle aufgerufen werden.
So wird etwa die Funktion $s\_mp\_clamp$ auch im Callstack der Subtraktions-Operation verwendet, sodass eine Überwachung dieser für die Shift-Operation falsche Ergebnisse liefern würde.

Die Funktion $s\_mp\_div\_2$ ist ein guter Kandidat für die Überwachung der Shift-Operation, da die benachbarten Funktionen keine Schnittmenge mit den aufgerufenen Funktion in der Subtraktionoperation haben.
Die Funktion liegt sowohl innerhalb der Cache-Line von 940 bis 97f als auch innerhalb der Cache-Line 980 bis 9af.

Angenommen es wird die Cache-Line von 980 bis 9af gewählt, dann wird auch Aktivität gemessen, sofern ausschließlich die Funktion $s\_mp\_mul\_2$ aufgerufen wird.

Die Überwachung der Cache-Line von 940 bis 97f dagegen schlägt auch dann an, wenn die Funktion $s\_mp\_rshd$ aufgerufen wird.
Dies passiert etwa im Zuge der Shift-Operation in weniger als 100 Taktzyklen nach dem Aufruf von $s\_mp\_div\_2$.
Sollte die Prime-and-Probe Dauer weniger als 100 Taktzyklen, würde die Gefahr bestehen fälschlicherweise zwei statt einer Shift-Operation zu messen.
Nach den in dieser Arbeit durchgeführten Tests scheint eine solche Dauer aber unrealistisch niedrig.
Daher eignet sich die Cache-Line von 940 bis 97f besser, da lediglich Funktionen überwacht werden, die Teil der Shift-Operation sind.

%TODO aufrufe naheligender Funktionen tracken um zu bewerten welche Adresse günstiger für eine Überwachung ist (zu vernachlässigen da nach pattern gesucht werden kann)
%Am besten geeignet scheint die $s\_mp\_idv\_2d$-Funktion zu sein, da sich dessen Code TODO Bytes groß ist und sich so über mehr als eine Cache-Line spannt.
%Die Funktion $s\_mp\_div\_2$ liegt ungünstiger im Code, da unmittelbar davor die $s\_mp\_rshd$-Funktion und danach die $s\_mp\_mul\_2$-Funktion liegt, welche beide in einem anderen Kontext innerhalb der Schlüsselgenerierung verwendet werden.

Die Subtraktions-Operation wird durch die Funktion $mp\_sub$ umgesetzt, welche prüft welche Vorzeichen die Operanden besitzen und Abhängigkeit dessen weitere Funktion aufruft.
Es ist bekannt das bei der Subtraktion in Zeile 16 sowohl $u=e$ als auch $v=-t$ positiv sind, womit die Operanden die gleich Vorzeichen besitzen und die Funktion $s\_mp\_sub\_3arg$ aufgerufen wird.
Diese verwendet am Ende wieder die Funktion $s\_mp\_clamp$ um bei der Subtraktion entstandene führende Nullen zu entfernen.
Welche Adressen die Funktionen im Assemblercode haben, ist in Tabelle \ref{tbl:assOffsetSub} ersichtlich. 


\begin{table}[h]
\caption{Größe, Start- und Endadresse der für die Subtraktions-Operation relevanten Funktionen (fett hervorgehoben) sowie deren direkten Nachbarn im Assemblercode.}
\label{tbl:assOffsetSub}
\begin{tabular}{llll}
Funktion         & Startadresse & Endadresse & Differenz (Größe der Funktion) \\[10pt]
mp\_add & 8377$_{16}$ & 846f$_{16}$ & f8$_{16}$\\
\textbf{mp\_sub} & 8470$_{16}$ & 85c3$_{16}$ & 153$_{16}$ \\
mp\_mul & 85c4$_{16}$ & 894b$_{16}$ & 387$_{16}$ \\
%s\_mp\_add\_3arg & c738$_{16}$         & c913$_{16}$       & 1dc$_{16}$   \\
$\vdots$               &  $\vdots$             &    $\vdots$         &     $\vdots$   \\
s\_mp\_sub       & c914$_{16}$         & ca6a$_{16}$       & 157$_{16}$   \\
\textbf{s\_mp\_sub\_3arg} & ca6b$_{16}$         & cc01$_{16}$       & 197$_{16}$   \\
s\_mp\_mul       & cc02$_{16}$         & cc2a$_{16}$       & 29$_{16}$   
\end{tabular}
\end{table}

Geeignet für eine Überwachung der Subtraktionsfunktion ist die Funktion $mp\_sub$, wobei hierfür etwa die Cache-Line von 780 bis 7bf in Frage kommt.

Am Beginn des Angriffs steht die Angreiferin vor der Aufgabe, passende Eviction-Sets zu den für die Überwachung ausgewählten Cache-Lines zu suchen.
Hierzu wird sie die Schlüsselgenerierung manuell anstoßen und nach bestimmten Aktivitätsmustern in den überwachten Cache-Sets suchen.

Sobald eine beliebige Cache-Line einer 4-KiB Page einem Eviction-Set zugeordnet werden kann, sind auch alle anderen Zuordnungen dieser 4-KiB Page bekannt.
Daher genügt es die Cache-Line von b500 bis b53f einem Eviction-Set zuzuordnen, um ein Eviction-Set für die Cache-Line von b940 bis b97f zu finden, welche für die Überwachung der Shift-Operation genutzt werden kann.

Um die Werte $Z_i$ zu bestimmen muss die Prime-and-Probe mindestens die gleiche Geschwindigkeit wie die Shift bzw. Subtraktionfunktion erreichen.
In der Tabelle \ref{tbl:ShiftSubCycles} ist die durchschnittlichen der Zyklen für beide Funktion bei verschiedenen Schlüssellängen angegeben. Zum Vergleich wurde die Dauer der gesamten $mp_gcd$-Funktion hinzugefügt.
Die Dauer der Shift- sowie Subtraktionoperation hängt linear von der Schlüssellänge ab, wobei dies für die Dauer der gesamten $mp_gcd$-Funktion nicht der Fall ist.

\begin{table}[h]
\label{tbl:ShiftSubCycles}
\caption{Darstellung des linearen Zusammenhangs der Taktzyklendauer einer Shift- und Subtraktionsfunktion zu der Bitlänge. Als Vergleich die Dauer der gesamten GCD-Funktion ohne linearen Zusammenhang zu der Bitlänge. }
\begin{tabular}{llll}
Bitlänge    & 2048 & 4096 & 8192 \\
Shift       & 340  & 577  & 9597 \\
Subtraktion & 477  & 718  & 1223 \\
$mp\_gcd$    & 424K & 1,2M & 3,73M
\end{tabular}
\end{table}

Theoretisch wäre es möglich alleine durch die Zeitdifferenz zwischen zwei Subtraktionsfunktionen die Anzahl der Shift-Operationen zu bestimmen.
Wenn jedoch eine Auflösung von unter 330 Taktzyklen bereit steht, spricht nichts dagegen ausschließlich die Shift-Operation zu überwachen und bei Lücken in der Aktivität eine Subtraktionoperation anzunehmen.
Andersherum wird die Abschätzung sehr ungenau wenn nur eine Auflösung im Bereich der Subtraktions-Operationsdauer bereitsteht, da etwa der Unterschied zwischen einer und zwei zwischenzeitlichen Shift-Operationen fehleranfällig wird.

Die Prime-and-Probe Implementation in Javascript/Webassembly erwies sich als zu langsam um aufeinanderfolgende Shift-Operationen zu unterscheiden.
Wie in den Benchmarks in Kapitel 2 beschrieben dauert eine Prime-and-Probe Operation bei keiner Aktivität auf dem Cache-Set etwa 200ns was ca. 700 Taktzyklen entspricht.
Im Falle eines aktiven Cache-Set steigt die Dauer jedoch auf ca. 500ns (~1700 Taktzyklen) an.
Selbst für eine Schlüssellänge von 8192 Bit ist dieser Wert noch ungenügend hoch.

Auch in anderen Fällen ist die Geschwindigkeit der überwachten Funktion zu schnell um mittels der Prime-and-Probe Funktion überwacht zu werden.
Hierfür gibt es mehrere Vorschläge die Funktion künstlich auszubremsen, welche unter dem Begriff "performance degradation attacks" veröffentlicht wurden.
Eine trivialer Angriff ist etwa die Überwachung selber, da diese mit der Prime-Phase ein Cache-Set komplett füllt, sodass ein das Daten des angegriffenes Programms verdrängt werden und so aus dem langsamen Hauptspeicher geladen werden.
Der Effekt ist auch in umgekehrter Richtung also dem angegriffenen Programm auf das Angriffsprogramm vorhanden.
Die Differenz der Prime-and-Probe Dauer bei keiner gegenüber viel Aktivität auf dem Cache-Set veranschaulicht dies.

In anderen Kontexten wird häufig der $clflush$-Befehl verwendet um schnell und zuverlässig Daten aus dem Cache zu verdrängen. 
Ein Äquivalent existiert jedoch weder in Javascript noch in Webassembly.

Des Weiteren kann die Ausführung von Code im Browser nicht auf bestimmte CPU-Kerne fixiert werden. Hiermit sind Angriffe die einen Thread mit hoher Rechenlast auf den gleichen physischen Kern wie das Opferprogramm laufen lassen nicht ohne Weiteres möglich.

Der oben beschrieben triviale Angriff kann optimiert werden um Performancereduktion zu erhöhen. Dafür wird die Prime-and-Probe Operation ohne Zeitmessung für eine bestimmte Zeit in einer Endlosschleife, folgend Prime-Spam genannt, ausgeführt.

Wie oben beschrieben erstreckt sich der relevante Code für die Shift- und Subtraktionoperation über mehrere Funktionen und Cache-Lines.
Jeder dieser Cache-Line ist ein potenzielles Ziel für die Performancereduktion.
Da ein Prime-Spam auf eine Cache-Line einen kompletten physischen Kern auslastet, sollte das Ziel sorgfältig gewählt sein.

Um die Auswirkung vom Prime-Spam auf unterschiedliche Cache-Lines zu bewerten, wird die $mp\_gcd$-Funktion mit den Parametern $e=65535$ und $p-1$ ausgeführt.
$p$ ist eine zufällige aber über den gesamten Benchmarkzeitraum feste Pseudoprimzahl, wobei RSA-2048 als Parameter gewählt wurde.
Tabelle \ref{tbl:PerformanceDegShift} betrachtet alle Cache-Line, welche Code für die Shift-Operation beinhalten, wobei die Funktion $s\_mp\_clamp$ wie oben erwähnt auch in der Subtraktion-Operation verwendet wird.
Funktionen sind nicht auf Cache-Line-Grenzen alignt, weshalb die erste und letzte Cache-Lines eines Funktionscodes auch Code für andere Funktionen beinhaltet.

\begin{table}[h]
\label{tbl:PerformanceDegShift}
\caption{RSA-2048 Performance-Degradation-Attack mittels Prime-Spam auf Cache-Lines, welche Code der Shift-Operation beinhalten. 1. Spalte: Adressbereich der durch den Angriff verdrängten Cache-Line, 2. Spalte: Funktionen deren Code innerhalb des Adressbereichs der Cache-Line liegt, Spalte "Shift", "Subtraktion" und "$mp\_gcd"$: Mittlere Dauer der Shift-, Subtraktions-, bzw. $mp\_gcd$-Operation in Taktzyklen bei einem aktiven Angriff auf die in Spalte 1 spezifizierte Cache-Line. Die erste Zeile gibt die Referenzzeiten ohne aktiven Angriff an. }
\begin{tabular}{lllll}
Cache-Line  & Funktion(en) innerhalb der Cache-Line                                  & Shift & Subtraktion & mp\_gcd \\[10pt]
&Referenzzeiten ohne Prime-Spam                                         & 340   & 477         & 424k    \\
b800$_{16}$ - b83f$_{16}$ & $s\_mp\_free, s\_mp\_clamp$                 & 541   & 608         & 549k    \\
b840$_{16}$ - b87f$_{16}$ & $s\_mp\_clamp, s\_mp\_exch$                 & 538   & 605         & 553k    \\
bb40$_{16}$ - bb7f$_{16}$ & $s\_mp\_mul\_2d, s\_mp\_rshd$               & 450   & 514         & 479k    \\
bb80$_{16}$ - bbbf$_{16}$ & $s\_mp\_rshd$                               & 451   & 542         & 486k    \\
bbc0$_{16}$ - bbff$_{16}$ & $s\_mp\_rshd$                               & 486   & 563         & 581k    \\
bc00$_{16}$ - bc3f$_{16}$ & $s\_mp\_rshd$                               & 520   & 563         & 597k    \\
bc40$_{16}$ - bc7f$_{16}$ & $s\_mp\_rshd, s\_mp\_div\_2, s\_mp\_mul\_2$ & 480   & 503         & 474k    \\
be00$_{16}$ - be3f$_{16}$ & $s\_mp\_mod\_2d, s\_mp\_div\_2d$            & 511   & 560         & 544k    \\
be40$_{16}$ - be7f$_{16}$ & $s\_mp\_div\_2d$                            & 503   & 549         & 536k    \\
be80$_{16}$ - bebf$_{16}$ & $s\_mp\_div\_2d$                            & 539   & 557         & 551k    \\
bec0$_{16}$ - beff$_{16}$ & $s\_mp\_div\_2d$                            & 537   & 547         & 552k    \\
bf00$_{16}$ - bf3f$_{16}$ & $s\_mp\_div\_2d, s\_mp\_norm$               & 470   & 506         & 485k   
\end{tabular}
\end{table}

Die Referenzwerte stammen aus der Tabelle \ref{tbl:ShiftSubCycles}, welche unter dem selben Parameter $p-1$ entstanden sind.
Am besten geeignet sind die beiden Cache-Lines der $s\_mp\_clamp$-Funktion, da sie nicht nur Spitze in der Verlangsamung der Shift-Operation sind, sondern zusätzlich noch die Subtraktions-Operation besser als alle anderen bremsen.

Tabelle \ref{tbl:PerformanceDegSub} betrachtet alle Cache-Line, welche Code für die Subtraktions-Operation beinhalten, wobei Zeile 2 und 3 der Tabelle \ref{tbl:PerformanceDegShift} auch hier relevant sind.
Anders als bei der Shift-Operation bremsen bei der Subtraktions-Operation die Cache-Lines der $mp\_sub$ signifikant besser als die Cache-Lines der $s\_mp\_clamp$-Funktion.

\begin{table}[h]
\label{tbl:PerformanceDegSub}
\caption{RSA-2048 Performance-Degradation-Attack mittels Prime-Spam auf Cache-Lines, welche Code der Subtraktions-Operation beinhalten.
Spalteninhalte analog zu Tabelle \ref{tbl:PerformanceDegShift}}
\begin{tabular}{lllll}
Cache-Line & Funktion                     & Shift & Subtraktion & mp\_gcd \\[10pt]
&Referenzzeiten ohne Prime-Spam                         & 340   & 477         & 424k    \\
8440$_{16}$-847f$_{16}$  & $mp\_add, mp\_sub$             & 357   & 643         & 487k    \\
8480$_{16}$-84bf$_{16}$  & $mp\_sub$                      & 359   & 684         & 538k    \\
84c0$_{16}$-84ff$_{16}$  & $mp\_sub$                      & 362   & 681         & 531k    \\
8500$_{16}$-853f$_{16}$  & $mp\_sub$                      & 357   & 700         & 538k    \\
8540$_{16}$-857f$_{16}$  & $mp\_sub$                      & 362   & 683         & 534k    \\
8580$_{16}$-85cf$_{16}$  & $mp\_sub$                      & 358   & 732         & 534k    \\
85c0$_{16}$-85ff$_{16}$  & $mp\_sub, mp\_mul$            & 359   & 766         & 531k    \\
ca40$_{16}$-ca7f$_{16}$  & $s\_mp\_sub, s\_mp\_sub\_3arg$ & 357   & 643         & 490k    \\
ca80$_{16}$-cabf$_{16}$  & $s\_mp\_sub\_3arg$             & 359   & 644         & 494k    \\
cac0$_{16}$-caff$_{16}$  & $s\_mp\_sub\_3arg$             & 357   & 675         & 534k    \\
cb00$_{16}$-cb3f$_{16}$  & $s\_mp\_sub\_3arg$            & 358   & 669         & 536k    \\
cb40$_{16}$-cb7f$_{16}$  & $s\_mp\_sub\_3arg$             & 357   & 663         & 533k    \\
cb80$_{16}$-cbbf$_{16}$  & $s\_mp\_sub\_3arg$             & 359   & 676         & 546k    \\
cbc0$_{16}$-cbff$_{16}$  & $s\_mp\_sub\_3arg$             & 356   & 663         & 535k    \\
cc00$_{16}$-cc3f$_{16}$  & $s\_mp\_sub\_3arg, s\_mp\_mul$ & 352   & 571         & 483k   
\end{tabular}
\end{table}


Zusammenfassend kann die Shift-Operation bzw. Subtraktions-Operation durch einen Angriff maximal von 340 auf 541 Taktzyklen bzw. von 477 auf 766 gebremst werden, welches einer Verlangsamung von \~59\% respektive \~61\% entspricht.
Tests haben ergeben, dass sich bei RSA-4096 und RSA-8192 die gleichen prozentualen Differenzen erzielen lassen.

Die beiden Cache-Lines der $s\_mp\_clamp$-Funktion sind dabei zu bevorzugen, da sie beide Operationen gleichzeitig gut bis sehr gut bremsen.
Des Weiteren sollte der Foksu auf das Bremsen der Shift-Operation gelegt werden, da diese zum einen schneller ist und die Unterscheidung einzelner Shift-Operation für Rekonstruktion der Primzahl wesentlich ist.
Zum anderen Bremsen viele der Cache-Lines mit Shift-Operationscode auch die Subtraktion-Funktion messbar, wobei dieses Phänomen andersherum nicht beobachtet werden kann.
TODO warum??

TODO mini bench einfügen

TODO multithread bench

%TODO slowdown Techniken und benchmarks auf verschiedene codeteile beschreiben\\
%TODO wie schnell ist javascript, eventuell in Kapitel 2 näher beschreiben


%TODO beschreiben warum der angriff so nicht in wasm/js möglich ist, warum er in c möglich ist, clflush vs prime spam usw.

%rsa und storeforward näher zu kapiteln bringen anstatt in grundlagen?
%speicher deduplizierung?
%grundlagen ganz vorner hier gehört die erklärung des themas hin, sowie %relvanz für die forschuing
%titel anpassen